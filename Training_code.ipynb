{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIHkfCOFTjRb"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow.compat.v1.keras.backend as K\n",
        "import tensorflow as tf\n",
        "#tf.compat.v1.disable_eager_execution()\n",
        "#import tensorflow as tf\n",
        "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "#tf.enable_eager_execution()\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "#from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QckilSYlUrn5",
        "outputId": "f590b581-bf6a-40a5-af63-203d60a8058b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdTndyNkUsVt",
        "outputId": "16b7077a-4303-4354-8c7d-51f0248854d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version:  2.15.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.16.1\n",
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLKfHWqqUvim"
      },
      "outputs": [],
      "source": [
        "#root_dir = \"/content/drive/MyDrive/Kaggle_Datasets/plantdisease/PlantVillage\"\n",
        "\n",
        "train_dir = \"/content/drive/MyDrive/processed_data/train\"\n",
        "val_dir = \"/content/drive/MyDrive/processed_data/val\"\n",
        "test_dir = \"/content/drive/MyDrive/processed_data/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDIeBh3xUzcR"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "from os.path import exists\n",
        "\n",
        "def count(dir, counter=0):\n",
        "    \"returns number of files in dir and subdirs\"\n",
        "    for pack in os.walk(dir):\n",
        "        for f in pack[2]:\n",
        "            counter += 1\n",
        "    return dir + \" : \" + str(counter) + \"files\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHda_6GGU3YD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62080f74-363e-48d6-98ef-a5d1ab05b013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total images for training : /content/drive/MyDrive/processed_data/train : 11464files\n",
            "total images for validation : /content/drive/MyDrive/processed_data/val : 1431files\n",
            "total images for validation : /content/drive/MyDrive/processed_data/test : 1437files\n"
          ]
        }
      ],
      "source": [
        "print('total images for training :', count(train_dir))\n",
        "print('total images for validation :', count(val_dir))\n",
        "print('total images for validation :', count(test_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ihbd92WFU_l-"
      },
      "outputs": [],
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crE8ISJVVAnJ",
        "outputId": "5edc9398-878d-4a36-e978-7753621fefc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1431 images belonging to 5 classes.\n",
            "Found 11464 images belonging to 5 classes.\n",
            "Found 1437 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "# Create an ImageDataGenerator for validation data (no data augmentation)\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    shuffle=False,\n",
        "    seed=42,\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "do_data_augmentation = False\n",
        "if do_data_augmentation:\n",
        "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=40,\n",
        "        horizontal_flip=True,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "else:\n",
        "    train_datagen = validation_datagen  # Use the same normalization for training data\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    subset=\"training\",\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the number of classes dynamically\n",
        "num_classes = len(train_generator.class_indices)"
      ],
      "metadata": {
        "id": "I14xOxfSjr53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "LBKON6gcv5Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base =  tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
        "    input_shape= list(IMAGE_SHAPE)+[3],\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        ")\n",
        "\n",
        "# Add a global spatial average pooling layer\n",
        "out = base.output\n",
        "out = GlobalAveragePooling2D()(out)\n",
        "out=Dropout(0.4)(out)\n",
        "out = Dense(512, activation='relu')(out)\n",
        "out=Dropout(0.2)(out)\n",
        "predictions = Dense(5, activation='softmax')(out)\n",
        "model = Model(inputs=base.input, outputs=predictions)\n",
        "\n",
        "# only if we want to freeze layers\n",
        "for layer in base.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "base.layers[-1].trainable =True\n",
        "\n",
        "# Compile\n",
        "#opt = Adam(lr=learning_rate, decay=learning_rate / EPOCHS)\n",
        "\n",
        "LEARNING_RATE = 0.1\n",
        "model.compile(\n",
        "   optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),loss='categorical_crossentropy',metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "GcfK3BVT3GLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    min_delta=0.01,\n",
        "    patience=3,\n",
        "    factor=0.25,\n",
        "    verbose=1,\n",
        "    cooldown=0,\n",
        "    min_lr=0.00000001\n",
        ")\n",
        "\n",
        "early_stopper = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    min_delta=0.005,\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "OFRZ7pUwj0iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhB9L3t4eG2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab7fc4d-e1f4-4a99-d2d2-20be52b92057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 279s 32s/step - loss: 273.8210 - accuracy: 0.2285 - val_loss: 40.5978 - val_accuracy: 0.2180\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7954f0154e50>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import pickle\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "EPOCHS = 30\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint_path = '/content/drive/MyDrive/mobilenet_model_checkpoint.h5'\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
        "early_stopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "\n",
        "# Attempt to train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=8,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator),\n",
        "    #callbacks=[reduce_lr, early_stopper, checkpoint_callback]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage: Evaluate model on test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "7ChTwQ7pj_us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot Training and Validation Accuracy\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy', color='blue')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy', color='orange')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot Training and Validation Loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs_range, loss, label='Training Loss', color='blue')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss', color='orange')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tmzPK1b8kBK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMJO1Pu7VdzJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "\n",
        "#plt.savefig('/content/drive/MyDrive/after_30_epoch_accuracy.png')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.show()\n",
        "#plt.savefig('/content/drive/MyDrive/after_30_epoch_loss.png')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import OpenCV\n",
        "import cv2\n",
        "\n",
        "# Utility\n",
        "import itertools\n",
        "import random\n",
        "from collections import Counter\n",
        "from glob import iglob\n",
        "\n",
        "def load_image(filename):\n",
        "    img = cv2.imread(os.path.join(root_dir, val_dir, filename))\n",
        "    assert not isinstance(img,type(None)), 'image not found'\n",
        "\n",
        "    img = cv2.resize(img, (IMAGE_SHAPE[0], IMAGE_SHAPE[1]) )\n",
        "\n",
        "    img = img /255\n",
        "\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def predict(image):\n",
        "    probabilities = model.predict(np.asarray([img]))[0]\n",
        "    class_idx = np.argmax(probabilities)\n",
        "\n",
        "    return {classes[class_idx]: probabilities[class_idx]}"
      ],
      "metadata": {
        "id": "RVDp4I2WkDnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, \"/content/drive/MyDrive/Models/mobileNet_saved_on_2_epoch\")"
      ],
      "metadata": {
        "id": "XiVNsbb5RayR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def display_batch(generator):\n",
        "    images, labels = next(generator)\n",
        "    for i in range(len(images)):\n",
        "        plt.imshow(images[i])\n",
        "        plt.title(f\"Label: {np.argmax(labels[i])}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# Display the first batch of test images and their labels\n",
        "display_batch(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "xs3AToNyY9sl",
        "outputId": "85781c7e-bd88-4682-9b99-25810557f36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-4b5aeb736681>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Display the first batch of test images and their labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdisplay_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-4b5aeb736681>\u001b[0m in \u001b[0;36mdisplay_batch\u001b[0;34m(generator)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Label: {np.argmax(labels[i])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYViKbGPVk_l"
      },
      "outputs": [],
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/drive/MyDrive/efficientnet_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/content/drive/MyDrive/mobilenetNet.h5\")\n",
        "print(\"Saved model to disk\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}